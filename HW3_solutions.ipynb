{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3: Confidence Intervals and Bootstrap\n",
    "\n",
    "**Due**: Tuesday Apr 25th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW Logistics\n",
    "\n",
    "- **Release**: Every week there will be a HW assignment released on *Wednesday* and due the following *Tuesday at 11:59pm*. \n",
    "Homework will be posted to the course website. \n",
    "- **Format**: We expect students to complete the homework notebooks using Google Colab (see Discussion 1), but this is not explicitly required and you may use whatever software you would like to run notebooks. \n",
    "- **Answers**: As a general guiding policy, you should always try to make it as clear as possible what your answer to each question is, and how you arrived at your answer. Generally speaking, this will mean including all code used to generate results, outputting the actual results to the notebook, and (when necessary) including written answers to support your code.\n",
    "- **Submission**: Homeworks will be *submitted to Gradescope*, and we expect all students to do question matching on Gradescope upon submission.\n",
    "- **Late Policy**: All students are allowed 7 total slip days for the quarter, and at most 5 can be used for a single HW assignment. There will be no late credit if you have used up all your slip days. Also, your lowest HW grade will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Time Spent on HW\n",
    "\n",
    "Course staff is interested in understanding how much time students spend on homework assignments. Based on data from previous years, you are told that the true distribution for hours spent on homework is the following discrete distribution:\n",
    "\n",
    "<center>\n",
    "\n",
    "| Hours | 1 | 2 | 3 | 4 | 5 |\n",
    "|---|---|---|---|---|---|\n",
    "| Probability | 0.05 | 0.1 | 0.25 | 0.45 | 0.15 |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part (a)**: What is the expected value of the above distribution? What is the variance? Write code to show the calculations used to arrive at your answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean hours: 3.55\n",
      "Variance of hours: 1.05\n"
     ]
    }
   ],
   "source": [
    "# The mean is sum_j x_j p_j\n",
    "hours = np.array([1, 2, 3, 4, 5])\n",
    "probs = np.array([0.05, 0.1, 0.25, 0.45, 0.15])\n",
    "mean_hours = np.sum(hours * probs)\n",
    "print(f\"Mean hours: {mean_hours}\")\n",
    "\n",
    "# The variance is EX^2 - (EX)^2\n",
    "var_hours = np.sum(hours**2 * probs) - mean_hours**2\n",
    "print(f\"Variance of hours: {np.round(var_hours, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part (b)**: Generate a sample of size $n = 100$ (with replacement) from the above distribution. Use your sample to calculate a point estimate for the mean and variance of the distribution. Lastly, calculate a 95% confidence interval for the mean of the distribution, using the analytical formula to estimate the standard error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample mean: 3.49\n",
      "Sample var: 1.06\n",
      "CI: (3.2882, 3.6918)\n"
     ]
    }
   ],
   "source": [
    "# Set seed\n",
    "np.random.seed(10)\n",
    "\n",
    "# -------  Write code below ---------- #\n",
    "hours_df = pd.DataFrame({\n",
    "    \"hours\": hours,\n",
    "    \"probs\": probs\n",
    "})\n",
    "\n",
    "samples = hours_df.sample(n=100, weights=\"probs\", replace=True)[\"hours\"]\n",
    "print(f\"Sample mean: {samples.mean()}\")\n",
    "print(f\"Sample var: {np.round(samples.var(), 2)}\")\n",
    "\n",
    "stderr = np.sqrt(samples.var() / 100)\n",
    "print(f\"CI: ({np.round(samples.mean() - 1.96*stderr, 4)}, {np.round(samples.mean() + 1.96*stderr, 4)})\")\n",
    "\n",
    "# Also valid\n",
    "# print(f\"CI: ({stats.norm.interval(0.95, loc=samples.mean(), scale=stderr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part (c)**: Repeat the process from part (b) for 1000 trials, with each trial generating a new sample and corresponding point estimates and confidence intervals. For each trial, calculate whether or not the confidence interval contains the true mean calculated in part (a). In what percent of trials did the confidence interval contain the true mean? Does this align with expectations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage: 0.946\n"
     ]
    }
   ],
   "source": [
    "# Set seed\n",
    "np.random.seed(10)\n",
    "\n",
    "# -------  Write code below ---------- #\n",
    "\n",
    "n_trials = 1000\n",
    "covers = np.zeros(n_trials)\n",
    "for i in range(n_trials):\n",
    "    samples = hours_df.sample(n=100, weights=\"probs\", replace=True)[\"hours\"]\n",
    "    mean = samples.mean()\n",
    "    stderr = np.sqrt(samples.var() / 100)\n",
    "    lower = samples.mean() - 1.96*stderr\n",
    "    upper = samples.mean() + 1.96*stderr\n",
    "    covers[i] = mean_hours >= lower and mean_hours <= upper\n",
    "\n",
    "print(f\"Coverage: {covers.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get coverage on 94.6% of trials. If we constructed our confidence interval correctly, then we should expect to get coverage close to 95%, since are construction 95% confidence intervals, and indeed our coverage is close to 95%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Clickthrough rate\n",
    "\n",
    "Suppose a company has a website with an advertisement. The company believes that the ad is working if at least 30% of website visitors click on the ad. In order to access whether or not the ad is successful, the company collects data for 50 website visitors, of which 18 click on the advertisement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part (a)**: Calculate a point estimate for the clickthrough rate, i.e. the proportion of website visitors that clicked on the ad. Then, calculate a 95% confidence interval for the clickthrough rate using the analytical formula to estimate the standard error. Based on your CI, do you think you should tell the company that the ad is work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CI: (0.227, 0.493)\n"
     ]
    }
   ],
   "source": [
    "phat = 18 / 50\n",
    "stderr = np.sqrt(phat * (1 - phat) / 50)\n",
    "print(f\"CI: {(np.round(phat - 1.96*stderr, 4), np.round(phat + 1.96*stderr, 4))}\")\n",
    "# Also valid\n",
    "# print(f\"CI: ({stats.norm.interval(0.95, loc=phat, scale=stderr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confidence interval contains 0.30, and so we cannot be very confident that the clickthrough rate is actually greater than 30%. Thus, we should tell the company that we do not know that the clickthrough rate is >30%. However, since the point estimate is >0.30, it would be reasonable to suggest that we should collect more data, and with more data, we may be able to more effectively conclude that the ad is working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part (b)**: Calculate a 95% confidence interval for the clickthrough rate based on *bootstrap* samples from the observed data, using both the percentile method and the normal approximation method. For each, use 1000 bootstrap replications. Is your recommendation to the company the same as in part (a)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentile CI: (0.22, 0.48)\n",
      "CI: (0.2212, 0.4808)\n"
     ]
    }
   ],
   "source": [
    "# Set seed\n",
    "np.random.seed(10)\n",
    "\n",
    "# -------  Write code below ---------- #\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"outcome\": [\"clicked\", \"not clicked\"],\n",
    "    \"prob\": [0.35, 0.65]\n",
    "})\n",
    "\n",
    "n_trials = 1000\n",
    "phats = np.zeros(n_trials)\n",
    "for i in range(n_trials):\n",
    "    samples = df.sample(n=50, weights=\"prob\", replace=True)\n",
    "    phats[i] = samples.groupby(\"outcome\").size()[\"clicked\"] / 50 \n",
    "\n",
    "print(f\"Percentile CI: ({np.percentile(phats, 2.5)}, {np.percentile(phats, 97.5)})\")\n",
    "boot_mean = phats.mean()\n",
    "boot_std = phats.std()\n",
    "# print(f\"Normal Approx CI: ({stats.norm.ppf(0.025, boot_mean, boot_std)}, {stats.norm.ppf(0.975, boot_mean, boot_std)})\")\n",
    "print(f\"CI: {(np.round(boot_mean - 1.96*boot_std, 4), np.round(boot_mean + 1.96*boot_std, 4))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both confidence intervals are very close to the confidence interval we obtained in part (a), and thus the recommendation is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: SAT Scores\n",
    "\n",
    "The file `sat_data.csv` contains a collection of SAT math, reading, and writing scores. Use the following code to read in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_data = pd.read_csv(\"https://raw.githubusercontent.com/stanford-mse-125/homework/main/data/sat_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part (a)**: Calculate a point estimate for the 80th percentile score in each subject area using the sat scores dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Critical_Reading_Score    528.2\n",
       "Math_Score                549.0\n",
       "Writing_Score             520.0\n",
       "Name: 0.8, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_data.quantile(0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part (b)**: Using the bootstrap percentile method, calculate 95\\% confidence intervals for the 80th percentile of SAT scores for each subject area. Print your resulting confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CI for Critical_Reading_Score: ((517.59, 536.0))\n",
      "CI for Math_Score: ((538.39, 563.4))\n",
      "CI for Writing_Score: ((511.4, 528.2))\n"
     ]
    }
   ],
   "source": [
    "# Set seed\n",
    "np.random.seed(10)\n",
    "\n",
    "# -------  Write code below ---------- #\n",
    "\n",
    "n_trials = 1000\n",
    "percentiles = np.zeros((n_trials, 3))\n",
    "for i in range(n_trials):\n",
    "    samples = sat_data.sample(n=sat_data.shape[0], replace=True)\n",
    "    percentiles[i, :] = samples.quantile(0.8)\n",
    "\n",
    "bootstrap_data = pd.DataFrame(percentiles, columns=sat_data.columns)\n",
    "\n",
    "for c in bootstrap_data.columns:\n",
    "    lower = bootstrap_data[c].quantile(0.025)\n",
    "    upper = bootstrap_data[c].quantile(0.975)\n",
    "    print(f\"CI for {c}: ({np.round(lower, 4), np.round(upper, 4)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part (c)**: If you look [here](https://blog.prepscholar.com/sat-historical-percentiles-for-2014-2013-2012-and-2011), you should notice that the actual 80th percentile scores from 2015 (the last year with 3 subject areas) are higher than the point estimates we obtained in part (a). List 2 reasons why the percentiles in our dataset may be lower. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer* A few examples:\n",
    "- The data is biased demographically, e.g. all samples come from a county with historically lower SAT scores.\n",
    "- The data comes from a year with abnormally low SAT scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part (d)**: Do you think the percentiles listed in the linked website from part (c) should have confidence intervals, like the ones we calculated in part (d)? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer*: They should not, because they are population statistics and thus there is not uncertainty."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
